optimism_package:
  chains:
    - participants:
      - el_type: op-geth
        el_log_level: ""
        el_extra_env_vars: {}
        el_extra_labels: {}
        el_extra_params: []
        el_tolerations: []
        el_volume_size: 0
        el_min_cpu: 0
        el_max_cpu: 0
        el_min_mem: 0
        el_max_mem: 0
        cl_type: op-node
        cl_log_level: ""
        cl_extra_env_vars: {}
        cl_extra_labels: {}
        cl_extra_params: []
        cl_tolerations: []
        cl_volume_size: 0
        cl_min_cpu: 0
        cl_max_cpu: 0
        cl_min_mem: 0
        cl_max_mem: 0
        node_selectors: {}
        tolerations: []
        count: 1
      network_params:
        network: "kurtosis"
        network_id: "2151908"
        seconds_per_slot: 2
        name: "op-kurtosis"
        fjord_time_offset: 0
        granite_time_offset: 0
        fund_dev_accounts: false
        withdrawal_delay: 604800 # should not be 0
        fee_withdrawal_network: 0 # 0 or 1 for either l1 or l2
        dispute_game_finality_delay: 302400 # should not be 0
      batcher_params:
        private_key: "e7848b12992369c383cfbff59633aeb305dbbd7a2c2ca19e60cc514dd953aefa"
        #signer_address: '0xD0e9d614E8d5C5C3e7F09Dcb31CB3A7552deC836'
        #signer_endpoint: 'http://host.docker.internal:4000/key/65021b59-0433-47e7-975d-0dcbfe898f9e'
        extra_params: []
      challenger_params:
        private_key: "e7848b12992369c383cfbff59633aeb305dbbd7a2c2ca19e60cc514dd953aefb"
        enabled: true
        extra_params: []
      sequencer_params:
        private_key: "e7848b12992369c383cfbff59633aeb305dbbd7a2c2ca19e60cc514dd953aefc"
      proposer_params:
        private_key: "e7848b12992369c383cfbff59633aeb305dbbd7a2c2ca19e60cc514dd953aefd"
      
      # currently these are ignored and have the address of the deployer, so that it has admin controls
      system_config_owner_params:
        address: "0xD7C403a8846c961Db06606BE89e04CD532d28f0B"      
      l1_proxy_admin_params:
        address: "0xCFDA3C8C66dd838BdC4A376b5259dce9064e9857"
      l2_proxy_admin_params: 
        address: "0xD3F2c5AFb2D76f5579F326b0cD7DA5F5a4126c35"
      gas_params:
        gas_limit: "0x17D7840"
        eip_1559_elasticity: 6
        eip_1559_denominator: 50
        base_fee_scalar: 2
        blob_base_fee_scalar: 1
      mev_params:
        builder_host: ""
        builder_port: ""
      additional_services: ["da_server"]

      da_server_params:
        # only if custom da_type selected in altda_deploy_config
        server_endpoint: "https://celestia-mocha-rpc.publicnode.com:443"

  op_contract_deployer_params:
    image: us-docker.pkg.dev/oplabs-tools-artifacts/images/op-deployer:v0.0.12
    l1_artifacts_locator: https://storage.googleapis.com/oplabs-contract-artifacts/artifacts-v1-fffcbb0ebf7f83311791534a41e65ef90df47797f9ca8f86941452f597f7128c.tar.gz
    l2_artifacts_locator: https://storage.googleapis.com/oplabs-contract-artifacts/artifacts-v1-fffcbb0ebf7f83311791534a41e65ef90df47797f9ca8f86941452f597f7128c.tar.gz
  global_log_level: "info"
  global_node_selectors: {}
  global_tolerations: []
  persistent: false

  altda_deploy_config:
    use_altda: true
    # TODO: Is this field redundant? Afaiu setting it to GenericCommitment will not deploy the
    # DAChallengeContract, and hence is equivalent to setting use_altda to false.
    # Furthermore, altda rollups using generic commitments might anyways need to support failing over
    # to keccak commitments if the altda layer is down.

    #da_provider: # not sure what this is from the docs https://docs.optimism.io/operators/chain-operators/configuration/rollup#gaspriceoraclebasefeescalar
    
    da_type: "" # auto, blobs, calldata or CUSTOM sets --data-availability-type in batcher_launcher
    da_batch_submission_frequency: 1 #--max-channel-duration=1 in block units but user input in minutes


    # below only if custom da selected
    da_commitment_type: KeccakCommitment # select either generic or Keccack
    
    # if select generic ask for da challenge contract address
    da_challenge_contract_address: "0x49cce536156dC6E5F05B26eaA8a2607Cb943e041"

    da_challenge_window: 100
    da_resolve_window: 100
    da_bond_size: 10000
    da_resolver_refund_percentage: 0

external_l1_network_params:
  network_id: "3151908"
  rpc_kind: standard
  el_rpc_url: http://el-1-geth-teku:8545 
  el_ws_url: ws://el-1-geth-teku:8546 
  cl_rpc_url: http://cl-1-teku-geth:4000 
  priv_key: "0xbcdf20249abf0ed6d944c0288fad489e33f66b3960d9e6229c1cd214ed3bbe31"

# external_l1_network_params:
#   network_id: "11155111"
#   rpc_kind: quicknode
#   el_rpc_url: https://omniscient-sparkling-model.ethereum-sepolia.quiknode.pro/0650b5f675a2d17b00c8aa2a29dadc3e46f7fdbb/
#   el_ws_url: wss://omniscient-sparkling-model.ethereum-sepolia.quiknode.pro/0650b5f675a2d17b00c8aa2a29dadc3e46f7fdbb/
#   cl_rpc_url: https://omniscient-sparkling-model.ethereum-sepolia.quiknode.pro/0650b5f675a2d17b00c8aa2a29dadc3e46f7fdbb/
#   priv_key: "0xbcdf20249abf0ed6d944c0288fad489e33f66b3960d9e6229c1cd214ed3bbe31"

# ethereum_package:
#   participants:
#   - el_type: geth
#     cl_type: teku
#     cl_image: "consensys/teku:latest-amd64" # add this https://github.com/rancher-sandbox/rancher-desktop/issues/8057
#   network_params:
#     preset: minimal
#     genesis_delay: 5
#     additional_preloaded_contracts: '
#       {
#         "0x4e59b44847b379578588920cA78FbF26c0B4956C": {
#           "balance": "0ETH",
#           "code": "0x7fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffe03601600081602082378035828234f58015156039578182fd5b8082525050506014600cf3",
#           "storage": {},
#           "nonce": "1"
#         }
#       }
#     '
